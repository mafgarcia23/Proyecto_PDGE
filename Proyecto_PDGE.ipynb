{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto #2\n",
        "* Materia : Procesamiento de datos a Gran Escala\n",
        "* Realizado por : Ana Maria Sanchez, Valentina Delgado ,\n",
        "Maria Fernanda García\n",
        "* Carrera: Ciencia de Datos\n",
        "* Presentado a : John Corredor\n",
        "* Fecha: 11/11/2013\n",
        "\n"
      ],
      "metadata": {
        "id": "TLwOedJGvKNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMeQQhvEl7mC",
        "outputId": "8f4dd025-ffaa-4d86-f459-b6a74ab68f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=6cc4e62427ad663eb5efbfe385df81ad48b37794f905c97068b5c15e4889ddc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hh-U54wTlrF5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import count, when\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementamos todo lo necesario para aplicar Spark"
      ],
      "metadata": {
        "id": "MRKG0gIfwn5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fsOKI8BXlwpx"
      },
      "outputs": [],
      "source": [
        "# Crear una SparkSession\n",
        "spark = SparkSession.builder.appName(\"Lectura de Datos\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Información general de los Datasets que tenemos"
      ],
      "metadata": {
        "id": "Rh_f0qcLwwsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3SE4VaHpzsJ",
        "outputId": "e6df6baf-57d3-47f4-8612-30d34ea9165d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----------+-------------------+--------------------+-----------+-------------+----------+----------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "|UNIQUE_ID|COLLISION_ID|CRASH_DATE|         CRASH_TIME|           PERSON_ID|PERSON_TYPE|PERSON_INJURY|VEHICLE_ID|PERSON_AGE|   EJECTION|EMOTIONAL_STATUS|       BODILY_INJURY| POSITION_IN_VEHICLE|  SAFETY_EQUIPMENT|        PED_LOCATION|          PED_ACTION|           COMPLAINT|       PED_ROLE|CONTRIBUTING_FACTOR_1|CONTRIBUTING_FACTOR_2|PERSON_SEX|\n",
            "+---------+------------+----------+-------------------+--------------------+-----------+-------------+----------+----------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "| 10249006|     4229554|10/26/2019|2023-11-12 09:43:00|31aa2bc0-f545-444...|   Occupant|  Unspecified|  19141108|      NULL|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         U|\n",
            "| 10255054|     4230587|10/25/2019|2023-11-12 15:15:00|4629e500-a73e-48d...|   Occupant|  Unspecified|  19144075|        33|Not Ejected|  Does Not Apply|      Does Not Apply|Front passenger, ...|Lap Belt & Harness|                NULL|                NULL|      Does Not Apply|      Passenger|                 NULL|                 NULL|         F|\n",
            "| 10253177|     4230550|10/26/2019|2023-11-12 17:55:00|ae48c136-1383-45d...|   Occupant|  Unspecified|  19143133|        55|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         M|\n",
            "|  6650180|     3565527|11/21/2016|2023-11-12 13:05:00|             2782525|   Occupant|  Unspecified|      NULL|      NULL|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|Notified Person|                 NULL|                 NULL|      NULL|\n",
            "| 10255516|     4231168|10/25/2019|2023-11-12 11:16:00|e038e18f-40fb-447...|   Occupant|  Unspecified|  19144329|         7|Not Ejected|  Does Not Apply|      Does Not Apply|Right rear passen...|          Lap Belt|                NULL|                NULL|      Does Not Apply|      Passenger|                 NULL|                 NULL|         F|\n",
            "| 10253606|     4230743|10/24/2019|2023-11-12 19:15:00|84bcb3a7-d201-4c6...|   Occupant|      Injured|  19143343|        27|Not Ejected|       Conscious|                Back|              Driver|Lap Belt & Harness|                NULL|                NULL|Complaint of Pain...|         Driver|                 NULL|                 NULL|         M|\n",
            "| 10251336|     4230047|10/26/2019|2023-11-12 16:45:00|21064a07-a945-49d...|   Occupant|  Unspecified|  19142198|        41|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         F|\n",
            "| 10248708|     4229547|10/26/2019|2023-11-12 01:15:00|a8904763-2870-42f...| Pedestrian|      Injured|      NULL|        24|       NULL|       Conscious|Shoulder - Upper Arm|                NULL|              NULL|Pedestrian/Bicycl...|Crossing With Signal|        None Visible|     Pedestrian|          Unspecified|          Unspecified|         F|\n",
            "| 10250179|     4229808|10/26/2019|2023-11-12 13:04:00|c3fc715e-203f-462...|   Occupant|  Unspecified|  19141630|        36|Not Ejected|  Does Not Apply|      Does Not Apply|              Driver|Lap Belt & Harness|                NULL|                NULL|      Does Not Apply|         Driver|                 NULL|                 NULL|         M|\n",
            "| 10253792|     4230915|10/24/2019|2023-11-12 08:20:00|793ac6c6-cbc7-4ab...|   Occupant|  Unspecified|  19143438|      NULL|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         U|\n",
            "+---------+------------+----------+-------------------+--------------------+-----------+-------------+----------+----------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Lee un archivo CSV\n",
        "df1 = spark.read.csv(\"Motor_Vehicle_Collisions_-_Person_20231102.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Muestra el DataFrame\n",
        "df1.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yGVgfc2ttt5",
        "outputId": "be9c6c80-759d-4766-aee8-e37493dcc01a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['UNIQUE_ID',\n",
              " 'COLLISION_ID',\n",
              " 'CRASH_DATE',\n",
              " 'CRASH_TIME',\n",
              " 'PERSON_ID',\n",
              " 'PERSON_TYPE',\n",
              " 'PERSON_INJURY',\n",
              " 'VEHICLE_ID',\n",
              " 'PERSON_AGE',\n",
              " 'EJECTION',\n",
              " 'EMOTIONAL_STATUS',\n",
              " 'BODILY_INJURY',\n",
              " 'POSITION_IN_VEHICLE',\n",
              " 'SAFETY_EQUIPMENT',\n",
              " 'PED_LOCATION',\n",
              " 'PED_ACTION',\n",
              " 'COMPLAINT',\n",
              " 'PED_ROLE',\n",
              " 'CONTRIBUTING_FACTOR_1',\n",
              " 'CONTRIBUTING_FACTOR_2',\n",
              " 'PERSON_SEX']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoHLY24a9j6S",
        "outputId": "ab3b0af3-247e-45b4-c1e7-dad6ca68c54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+----------+--------------------+-----------+-------------+--------------------+------------------+--------------+----------------+----------------+--------------------+----------------+--------------+--------------------+---------+--------+---------------------+---------------------+----------+\n",
            "|summary|         UNIQUE_ID|      COLLISION_ID|CRASH_DATE|           PERSON_ID|PERSON_TYPE|PERSON_INJURY|          VEHICLE_ID|        PERSON_AGE|      EJECTION|EMOTIONAL_STATUS|   BODILY_INJURY| POSITION_IN_VEHICLE|SAFETY_EQUIPMENT|  PED_LOCATION|          PED_ACTION|COMPLAINT|PED_ROLE|CONTRIBUTING_FACTOR_1|CONTRIBUTING_FACTOR_2|PERSON_SEX|\n",
            "+-------+------------------+------------------+----------+--------------------+-----------+-------------+--------------------+------------------+--------------+----------------+----------------+--------------------+----------------+--------------+--------------------+---------+--------+---------------------+---------------------+----------+\n",
            "|  count|            138102|            138102|    138102|              138101|     138102|       138102|              105672|            109497|         58231|           67651|           67673|               58292|           58276|         11131|               11099|    67671|  133426|                 9839|                 9823|    108594|\n",
            "|   mean| 7806895.084242082|3753199.1966589913|      NULL|  1384657.2328621636|       NULL|         NULL|1.8087574285364147E7| 37.03000082194033|          NULL|            NULL|            NULL|                NULL|            NULL|          NULL|                NULL|     NULL|    NULL|                 NULL|                 NULL|      NULL|\n",
            "| stddev|2018203.5057836769| 567708.1525711421|      NULL|   985152.3863069632|       NULL|         NULL|  1332244.1944478082|104.59241635646141|          NULL|            NULL|            NULL|                NULL|            NULL|          NULL|                NULL|     NULL|    NULL|                 NULL|                 NULL|      NULL|\n",
            "|    min|            106541|               790|01/01/2013|00015b04-649e-44b...|  Bicyclist|      Injured|             2670776|              -999|Does Not Apply|  Apparent Death|Abdomen - Pelvis|Any person in the...|               -|Does Not Apply|Crossing Against ...| Abrasion|  Driver| Aggressive Drivin...| Aggressive Drivin...|         F|\n",
            "|    max|          12701255|           4652114|12/31/2022|ffff6cba-4a49-47b...| Pedestrian|  Unspecified|            20493043|              9999|       Unknown|         Unknown|         Unknown|             Unknown|         Unknown|       Unknown|  Working in Roadway| Whiplash| Witness| View Obstructed/L...| View Obstructed/L...|         U|\n",
            "+-------+------------------+------------------+----------+--------------------+-----------+-------------+--------------------+------------------+--------------+----------------+----------------+--------------------+----------------+--------------+--------------------+---------+--------+---------------------+---------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Información de columnas\n",
        "df1.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2u8USDCWqLyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace78d41-738d-405d-851f-54525a476751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+---------+--------+---------+----------+--------------------+--------------------+--------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "|CRASH DATE|         CRASH TIME|  BOROUGH|ZIP CODE| LATITUDE| LONGITUDE|            LOCATION|      ON STREET NAME|   CROSS STREET NAME|     OFF STREET NAME|NUMBER OF PERSONS INJURED|NUMBER OF PERSONS KILLED|NUMBER OF PEDESTRIANS INJURED|NUMBER OF PEDESTRIANS KILLED|NUMBER OF CYCLIST INJURED|NUMBER OF CYCLIST KILLED|NUMBER OF MOTORIST INJURED|NUMBER OF MOTORIST KILLED|CONTRIBUTING FACTOR VEHICLE 1|CONTRIBUTING FACTOR VEHICLE 2|CONTRIBUTING FACTOR VEHICLE 3|CONTRIBUTING FACTOR VEHICLE 4|CONTRIBUTING FACTOR VEHICLE 5|COLLISION_ID| VEHICLE TYPE CODE 1| VEHICLE TYPE CODE 2|VEHICLE TYPE CODE 3|VEHICLE TYPE CODE 4|VEHICLE TYPE CODE 5|\n",
            "+----------+-------------------+---------+--------+---------+----------+--------------------+--------------------+--------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "|09/11/2021|2023-11-12 02:39:00|     NULL|    NULL|     NULL|      NULL|                NULL|WHITESTONE EXPRES...|           20 AVENUE|                NULL|                        2|                       0|                            0|                           0|                        0|                       0|                         2|                        0|         Aggressive Drivin...|                  Unspecified|                         NULL|                         NULL|                         NULL|     4455765|               Sedan|               Sedan|               NULL|               NULL|               NULL|\n",
            "|03/26/2022|2023-11-12 11:45:00|     NULL|    NULL|     NULL|      NULL|                NULL|QUEENSBORO BRIDGE...|                NULL|                NULL|                        1|                       0|                            0|                           0|                        0|                       0|                         1|                        0|            Pavement Slippery|                         NULL|                         NULL|                         NULL|                         NULL|     4513547|               Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|06/29/2022|2023-11-12 06:55:00|     NULL|    NULL|     NULL|      NULL|                NULL|  THROGS NECK BRIDGE|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|         Following Too Clo...|                  Unspecified|                         NULL|                         NULL|                         NULL|     4541903|               Sedan|       Pick-up Truck|               NULL|               NULL|               NULL|\n",
            "|09/11/2021|2023-11-12 09:35:00| BROOKLYN|   11208|40.667202|  -73.8665|(40.667202, -73.8...|                NULL|                NULL|1211      LORING ...|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|                  Unspecified|                         NULL|                         NULL|                         NULL|                         NULL|     4456314|               Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 08:13:00| BROOKLYN|   11233|40.683304|-73.917274|(40.683304, -73.9...|     SARATOGA AVENUE|      DECATUR STREET|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|                         NULL|                         NULL|                         NULL|                         NULL|                         NULL|     4486609|                NULL|                NULL|               NULL|               NULL|               NULL|\n",
            "|04/14/2021|2023-11-12 12:47:00|     NULL|    NULL|     NULL|      NULL|                NULL|MAJOR DEEGAN EXPR...|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|                  Unspecified|                  Unspecified|                         NULL|                         NULL|                         NULL|     4407458|                Dump|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 17:05:00|     NULL|    NULL|40.709183|-73.956825|(40.709183, -73.9...|BROOKLYN QUEENS E...|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|          Passing Too Closely|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486555|               Sedan|Tractor Truck Diesel|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 08:17:00|    BRONX|   10475| 40.86816| -73.83148|(40.86816, -73.83...|                NULL|                NULL|344       BAYCHES...|                        2|                       0|                            0|                           0|                        0|                       0|                         2|                        0|                  Unspecified|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486660|               Sedan|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 21:10:00| BROOKLYN|   11207| 40.67172|  -73.8971|(40.67172, -73.8971)|                NULL|                NULL|2047      PITKIN ...|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|          Driver Inexperience|                  Unspecified|                         NULL|                         NULL|                         NULL|     4487074|               Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 14:58:00|MANHATTAN|   10017| 40.75144| -73.97397|(40.75144, -73.97...|            3 AVENUE|      EAST 43 STREET|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|          Passing Too Closely|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486519|               Sedan|Station Wagon/Spo...|               NULL|               NULL|               NULL|\n",
            "|12/13/2021|2023-11-12 00:34:00|     NULL|    NULL|40.701275| -73.88887|(40.701275, -73.8...|       MYRTLE AVENUE|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|         Passing or Lane U...|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486934|Station Wagon/Spo...|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 16:50:00|   QUEENS|   11413|40.675884| -73.75577|(40.675884, -73.7...|SPRINGFIELD BOULE...|     EAST GATE PLAZA|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|           Turning Improperly|                  Unspecified|                         NULL|                         NULL|                         NULL|     4487127|               Sedan|Station Wagon/Spo...|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 08:30:00|     NULL|    NULL|     NULL|      NULL|                NULL|            broadway|west 80 street -w...|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|         Unsafe Lane Changing|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486634|Station Wagon/Spo...|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 00:59:00|     NULL|    NULL| 40.59662| -74.00231|(40.59662, -74.00...|        BELT PARKWAY|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|                 Unsafe Speed|                         NULL|                         NULL|                         NULL|                         NULL|     4486564|               Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 23:10:00|   QUEENS|   11434| 40.66684| -73.78941|(40.66684, -73.78...|NORTH CONDUIT AVENUE|          150 STREET|                NULL|                        2|                       0|                            0|                           0|                        0|                       0|                         2|                        0|         Reaction to Uninv...|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486635|               Sedan|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 17:58:00| BROOKLYN|   11217| 40.68158| -73.97463|(40.68158, -73.97...|                NULL|                NULL|480       DEAN ST...|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|          Passing Too Closely|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486604|              Tanker|Station Wagon/Spo...|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 20:03:00| BROOKLYN|   11226| 40.65068| -73.95881|(40.65068, -73.95...|                NULL|                NULL|878       FLATBUS...|                        4|                       0|                            0|                           0|                        0|                       0|                         4|                        0|             Steering Failure|                         NULL|                         NULL|                         NULL|                         NULL|     4486991|               Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 01:28:00|     NULL|    NULL|     NULL|      NULL|                NULL|       MEEKER AVENUE|      LORIMER STREET|                NULL|                        3|                       0|                            0|                           0|                        0|                       0|                         3|                        0|         Traffic Control D...|                  Unspecified|                         NULL|                         NULL|                         NULL|     4486284|Station Wagon/Spo...|Station Wagon/Spo...|               NULL|               NULL|               NULL|\n",
            "|12/11/2021|2023-11-12 19:43:00|    BRONX|   10463| 40.87262|-73.904686|(40.87262, -73.90...|WEST KINGSBRIDGE ...|        HEATH AVENUE|                NULL|                        1|                       0|                            0|                           0|                        0|                       0|                         1|                        0|                  Unspecified|                  Unspecified|                         NULL|                         NULL|                         NULL|     4487040|Station Wagon/Spo...|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 14:30:00|     NULL|    NULL|40.783268| -73.82485|(40.783268, -73.8...|WHITESTONE EXPRES...|                NULL|                NULL|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|         Following Too Clo...|                  Unspecified|                  Unspecified|                         NULL|                         NULL|     4486537|Station Wagon/Spo...|               Sedan|              Sedan|               NULL|               NULL|\n",
            "+----------+-------------------+---------+--------+---------+----------+--------------------+--------------------+--------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lee un archivo CSV\n",
        "df2 = spark.read.csv(\"Motor_Vehicle_Collisions_-_Crashes_20231102.csv\" , header=True, inferSchema=True)\n",
        "\n",
        "# Muestra el DataFrame\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5kBK5DGlt2cV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c9543c-3b0d-4305-e853-084708899d2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CRASH DATE',\n",
              " 'CRASH TIME',\n",
              " 'BOROUGH',\n",
              " 'ZIP CODE',\n",
              " 'LATITUDE',\n",
              " 'LONGITUDE',\n",
              " 'LOCATION',\n",
              " 'ON STREET NAME',\n",
              " 'CROSS STREET NAME',\n",
              " 'OFF STREET NAME',\n",
              " 'NUMBER OF PERSONS INJURED',\n",
              " 'NUMBER OF PERSONS KILLED',\n",
              " 'NUMBER OF PEDESTRIANS INJURED',\n",
              " 'NUMBER OF PEDESTRIANS KILLED',\n",
              " 'NUMBER OF CYCLIST INJURED',\n",
              " 'NUMBER OF CYCLIST KILLED',\n",
              " 'NUMBER OF MOTORIST INJURED',\n",
              " 'NUMBER OF MOTORIST KILLED',\n",
              " 'CONTRIBUTING FACTOR VEHICLE 1',\n",
              " 'CONTRIBUTING FACTOR VEHICLE 2',\n",
              " 'CONTRIBUTING FACTOR VEHICLE 3',\n",
              " 'CONTRIBUTING FACTOR VEHICLE 4',\n",
              " 'CONTRIBUTING FACTOR VEHICLE 5',\n",
              " 'COLLISION_ID',\n",
              " 'VEHICLE TYPE CODE 1',\n",
              " 'VEHICLE TYPE CODE 2',\n",
              " 'VEHICLE TYPE CODE 3',\n",
              " 'VEHICLE TYPE CODE 4',\n",
              " 'VEHICLE TYPE CODE 5']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TfOXCCI-oD6",
        "outputId": "558f0bf4-e984-426f-d792-35e39f23c8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|summary|CRASH DATE|      BOROUGH|          ZIP CODE|          LATITUDE|         LONGITUDE|            LOCATION|    ON STREET NAME| CROSS STREET NAME|     OFF STREET NAME|NUMBER OF PERSONS INJURED|NUMBER OF PERSONS KILLED|NUMBER OF PEDESTRIANS INJURED|NUMBER OF PEDESTRIANS KILLED|NUMBER OF CYCLIST INJURED|NUMBER OF CYCLIST KILLED|NUMBER OF MOTORIST INJURED|NUMBER OF MOTORIST KILLED|CONTRIBUTING FACTOR VEHICLE 1|CONTRIBUTING FACTOR VEHICLE 2|CONTRIBUTING FACTOR VEHICLE 3|CONTRIBUTING FACTOR VEHICLE 4|CONTRIBUTING FACTOR VEHICLE 5|     COLLISION_ID|VEHICLE TYPE CODE 1|VEHICLE TYPE CODE 2|VEHICLE TYPE CODE 3|VEHICLE TYPE CODE 4|VEHICLE TYPE CODE 5|\n",
            "+-------+----------+-------------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|  count|    170915|       112189|            112167|            156343|            156343|              156343|            124420|             79121|               46492|                   170915|                  170915|                       170915|                      170915|                   170915|                  170915|                    170915|                   170915|                       170050|                       132224|                        17224|                         4663|                         1417|           170915|             168853|             114028|              16003|               4412|               1367|\n",
            "|   mean|      NULL|         NULL|10889.455499389303|40.127169389020146|-72.83116396007276|                NULL| 463.6666666666667|55.285714285714285|                NULL|       0.4835912588128602|    0.002667992861948922|           0.0728724804727496|        0.001123365415557...|      0.04699411988415294|    1.755258461808501...|       0.34174297165257583|     0.001216979200187...|                         NULL|                         NULL|                         NULL|                         NULL|                         NULL|4475555.884632712|              666.0|             249.75|               NULL|               NULL|               NULL|\n",
            "| stddev|      NULL|         NULL| 524.1882373393258| 4.898499255978162| 8.889982766658969|                NULL|396.58836762231607| 69.45673542024628|                NULL|       0.8054511805378679|     0.05402156660549747|          0.27344246369662295|          0.0338454371237774|       0.2152725548976446|    0.013247492731129996|        0.7773252193892813|     0.037918851682349444|                         NULL|                         NULL|                         NULL|                         NULL|                         NULL|50198.28623437997|  570.7127123168013|              499.5|               NULL|               NULL|               NULL|\n",
            "|    min|01/01/2021|        BRONX|             10000|               0.0|        -74.254845|          (0.0, 0.0)|          1 AVENUE|                 0|1         AVIATIO...|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|         Accelerator Defec...|         Accelerator Defec...|         Aggressive Drivin...|         Aggressive Drivin...|          Alcohol Involvement|          3456194|        ''lime mope|                  0|             3-Door|             3-Door|      Armored Truck|\n",
            "|    max|12/31/2021|STATEN ISLAND|             11697|         40.912884|               0.0|(40.912884, -73.9...|     whythe avenue|   �ST 138 STREET|    w52nd stre12 ave|                       40|                       3|                            6|                           2|                        3|                       1|                        40|                        3|         Windshield Inadeq...|         View Obstructed/L...|         View Obstructed/L...|         View Obstructed/L...|                  Unspecified|          4664283|               �MBU|          x trailer|         vehicle tr|                van|                Van|\n",
            "+-------+----------+-------------+------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Información de columnas\n",
        "df2.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fTd31Pg4qeOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e8e2e7-cc22-40d7-9562-9771f5def44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----+--------------------+-----+--------------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
            "|ARREST_KEY|ARREST_DATE|PD_CD|             PD_DESC|KY_CD|           OFNS_DESC|  LAW_CODE|LAW_CAT_CD|ARREST_BORO|ARREST_PRECINCT|JURISDICTION_CODE|AGE_GROUP|PERP_SEX|     PERP_RACE|X_COORD_CD|Y_COORD_CD|          Latitude|         Longitude|             Lon_Lat|\n",
            "+----------+-----------+-----+--------------------+-----+--------------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
            "| 236791704| 11/22/2021|  581|                NULL| NULL|                NULL|PL 2225001|         M|          M|             28|                0|    45-64|       M|         BLACK|  997427.0|  230378.0|40.799008797000056|-73.95240854099995|POINT (-73.952408...|\n",
            "| 237354740| 12/04/2021|  153|              RAPE 3|  104|                RAPE|PL 1302502|         F|          B|             41|                0|    25-44|       M|WHITE HISPANIC| 1013232.0|  236725.0|40.816391847000034|-73.89529641399997|POINT (-73.895296...|\n",
            "| 236081433| 11/09/2021|  681|CHILD, ENDANGERIN...|  233|          SEX CRIMES|PL 2601001|         M|          Q|            113|                0|    25-44|       M|         BLACK| 1046367.0|  186986.0| 40.67970040800003|-73.77604736799998|POINT (-73.776047...|\n",
            "|  32311380| 06/18/2007|  511|CONTROLLED SUBSTA...|  235|     DANGEROUS DRUGS|PL 2200300|         M|          Q|             27|                1|    18-24|       M|         BLACK|      NULL|      NULL|              NULL|              NULL|                NULL|\n",
            "| 192799737| 01/26/2019|  177|        SEXUAL ABUSE|  116|          SEX CRIMES|PL 1306503|         F|          M|             25|                0|    45-64|       M|         BLACK| 1000555.0|  230994.0|40.800694331000045|-73.94110928599997|POINT (-73.941109...|\n",
            "| 193260691| 02/06/2019| NULL|                NULL| NULL|                NULL|PL 2203400|         F|          M|             14|                0|    25-44|       M|       UNKNOWN|  986685.0|  215375.0| 40.75783900300007|-73.99121211099998|POINT (-73.991212...|\n",
            "| 237291769| 12/03/2021|  579|                NULL| NULL|                NULL|PL 2224001|         F|          Q|            115|                0|    25-44|       M|         BLACK| 1018534.0|  220579.0| 40.77205649600006|-73.87622400099998|POINT (-73.876224...|\n",
            "| 236106641| 11/10/2021|  263|         ARSON 2,3,4|  114|               ARSON|PL 1501001|         F|          B|             41|               72|    25-44|       M|WHITE HISPANIC| 1017934.0|  232221.0|40.804012949000025|-73.87833183299993|POINT (-73.878331...|\n",
            "| 238383628| 12/28/2021|  729|FORGERY,ETC.,UNCL...|  113|             FORGERY|PL 1702500|         F|          Q|            113|                0|    18-24|       M|         BLACK| 1045482.0|  191341.0| 40.69166001700007|-73.77919852099996|POINT (-73.779198...|\n",
            "| 149117452| 01/06/2016|  153|              RAPE 3|  104|                RAPE|PL 1302503|         F|          K|             67|                0|    25-44|       M|         BLACK|  998032.0|  175598.0|40.648650085000035|-73.95033556299995|POINT (-73.950335...|\n",
            "| 237339209| 12/04/2021|  101|           ASSAULT 3|  344|ASSAULT 3 & RELAT...|PL 1200001|         M|          K|             83|                0|    25-44|       M|         BLACK| 1007400.0|  190154.0|40.688583516000044|-73.91652634699994|POINT (-73.916526...|\n",
            "| 221756278| 12/12/2020| NULL|                NULL| NULL|                NULL|PL 2203400|         F|          M|             23|                0|    25-44|       M|WHITE HISPANIC|  999998.0|  226211.0| 40.78756730100001|-73.94313233199995|POINT (-73.943132...|\n",
            "| 237580757| 12/09/2021|  105|   STRANGULATION 1ST|  106|      FELONY ASSAULT|PL 1211200|         F|          M|             30|                0|    25-44|       M|         BLACK|  999751.0|  241188.0| 40.82867545800008|-73.94398971599996|POINT (-73.943989...|\n",
            "| 190049060| 11/15/2018|  157|              RAPE 1|  104|                RAPE|PL 1303501|         F|          K|             77|                0|    25-44|       M|         BLACK| 1003606.0|  185050.0| 40.67458330800008|-73.93022154099998|POINT (-73.930221...|\n",
            "|  24288194| 09/13/2006|  203|TRESPASS 3, CRIMINAL|  352|   CRIMINAL TRESPASS|PL 140100E|         M|          K|             77|                2|    45-64|       M|         BLACK| 1004580.0|  183838.0| 40.67125445700003|     -73.926713851|POINT (-73.926713...|\n",
            "| 221870158| 12/15/2020|  297|FACILITATION 4, C...|  354|ANTICIPATORY OFFE...|PL 1150000|         M|          K|             75|                0|    45-64|       F|         BLACK| 1019745.0|  184405.0| 40.67276293200007|-73.87204263699994|POINT (-73.872042...|\n",
            "| 220422940| 11/12/2020|  157|              RAPE 1|  104|                RAPE|PL 1303502|         F|          Q|            112|                0|    25-44|       M|         BLACK| 1025420.0|  202485.0| 40.72236368700004|-73.85147389399998|POINT (-73.851473...|\n",
            "| 237954587| 12/16/2021|  397|ROBBERY,OPEN AREA...|  105|             ROBBERY|PL 1600500|         F|          M|              1|                0|    25-44|       M|         WHITE|  982351.0|  201758.0|40.720463840000036|-74.00685220399998|POINT (-74.006852...|\n",
            "| 189182271| 10/24/2018|  153|              RAPE 3|  104|                RAPE|PL 1302503|         F|          M|              5|                0|    45-64|       M|WHITE HISPANIC|  984946.0|  200203.0|40.716195914000025|-73.99749074599998|POINT (-73.997490...|\n",
            "| 222293770| 12/27/2020|  681|CHILD, ENDANGERIN...|  233|          SEX CRIMES|PL 2601001|         M|          B|             43|                0|    25-44|       M|         BLACK| 1020316.0|  239179.0| 40.82310129900002|-73.86969046099993|POINT (-73.869690...|\n",
            "+----------+-----------+-----+--------------------+-----+--------------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+----------+----------+------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lee un archivo CSV\n",
        "df3 = spark.read.csv(\"NYPD_Arrests_Data__Historic__20231102.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Muestra el DataFrame\n",
        "df3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hLArY9c0-sRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c8b992-f5d5-481a-9f23-055a190357b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-----------+-----------------+--------------------+-----------------+--------------------+----------+----------+-----------+-----------------+------------------+---------+--------+--------------------+------------------+-----------------+-------------------+-------------------+--------------------+\n",
            "|summary|          ARREST_KEY|ARREST_DATE|            PD_CD|             PD_DESC|            KY_CD|           OFNS_DESC|  LAW_CODE|LAW_CAT_CD|ARREST_BORO|  ARREST_PRECINCT| JURISDICTION_CODE|AGE_GROUP|PERP_SEX|           PERP_RACE|        X_COORD_CD|       Y_COORD_CD|           Latitude|          Longitude|             Lon_Lat|\n",
            "+-------+--------------------+-----------+-----------------+--------------------+-----------------+--------------------+----------+----------+-----------+-----------------+------------------+---------+--------+--------------------+------------------+-----------------+-------------------+-------------------+--------------------+\n",
            "|  count|              186957|     186957|           186900|              186735|           186735|              186735|    186952|    185456|     186957|           186957|            186957|   186957|  186957|              186957|            186956|           186956|             186956|             186956|              186956|\n",
            "|   mean|2.0436211348978642E8|       NULL|435.2008507223114|                NULL|254.4677216376148|                NULL|      NULL|      NULL|       NULL|63.16694213107827|1.7347785854501303|     NULL|    NULL|                NULL|1005571.8431609577|208195.2402222983| 40.738080425262254| -73.92303425260204|                NULL|\n",
            "| stddev|1.1955059674013432E7|       NULL|279.8570473309184|                NULL|153.1695603088002|                NULL|      NULL|      NULL|       NULL|34.71898635451871|11.677611498285136|     NULL|    NULL|                NULL|21487.823641783434| 30181.8694170402|0.08284719724312939|0.07749226404025371|                NULL|\n",
            "|    min|            10209522| 01/01/2019|                0|A.B.C.,FALSE PROO...|              101| ADMINISTRATIVE CODE|ABC00000MA|         F|          B|                1|                 0|    18-24|       F|AMERICAN INDIAN/A...|          914103.0|         121474.0|  40.49985023500005| -74.25225064499995|POINT (-73.700293...|\n",
            "|    max|           238451012| 12/31/2020|              997|WEAPONS,PROHIBITE...|              995|VEHICLE AND TRAFF...|VTL123400A|         V|          S|              123|                97|      <18|       M|      WHITE HISPANIC|         1067302.0|         271730.0|  40.91247643000003| -73.70029334799995|POINT (-74.252250...|\n",
            "+-------+--------------------+-----------+-----------------+--------------------+-----------------+--------------------+----------+----------+-----------+-----------------+------------------+---------+--------+--------------------+------------------+-----------------+-------------------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Información de columnas\n",
        "df3.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wOLsSi4buyjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2e89b0-421c-4d81-c8a8-3ec686bd2179"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ARREST_KEY',\n",
              " 'ARREST_DATE',\n",
              " 'PD_CD',\n",
              " 'PD_DESC',\n",
              " 'KY_CD',\n",
              " 'OFNS_DESC',\n",
              " 'LAW_CODE',\n",
              " 'LAW_CAT_CD',\n",
              " 'ARREST_BORO',\n",
              " 'ARREST_PRECINCT',\n",
              " 'JURISDICTION_CODE',\n",
              " 'AGE_GROUP',\n",
              " 'PERP_SEX',\n",
              " 'PERP_RACE',\n",
              " 'X_COORD_CD',\n",
              " 'Y_COORD_CD',\n",
              " 'Latitude',\n",
              " 'Longitude',\n",
              " 'Lon_Lat']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df3.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT_54BljsEPN"
      },
      "source": [
        "# Informacion General de los DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gGjLfE18sRth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8867fb2d-7e23-4c97-a4f7-d9d156e01937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de filas en el DataFrame uno:  138102\n",
            "Número de columnas en el DataFrame uno:  21\n",
            "----------------------------------------------\n",
            "Número de filas en el DataFrame dos: 170915\n",
            "Número de columnas en el DataFrame dos:  29\n",
            "----------------------------------------------\n",
            "Número de filas en el DataFrame tres:  186957\n",
            "Número de columnas en el DataFrame Tres:  19\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas en el DataFrame 1\n",
        "print(\"Número de filas en el DataFrame uno: \", df1.count())\n",
        "\n",
        "# Cantidad de columnas en el DataFrame\n",
        "print(\"Número de columnas en el DataFrame uno: \", len(df1.columns))\n",
        "\n",
        "print(\"----------------------------------------------\")\n",
        "\n",
        "# Cantidad de filas en el DataFrame 2\n",
        "print(\"Número de filas en el DataFrame dos:\", df2.count())\n",
        "\n",
        "# Cantidad de columnas en el DataFrame\n",
        "print(\"Número de columnas en el DataFrame dos: \", len(df2.columns))\n",
        "\n",
        "print(\"----------------------------------------------\")\n",
        "\n",
        "# Cantidad de filas en el DataFrame 3\n",
        "print(\"Número de filas en el DataFrame tres: \", df3.count())\n",
        "\n",
        "# Cantidad de columnas en el DataFrame\n",
        "print(\"Número de columnas en el DataFrame Tres: \", len(df3.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KQMTMco6vVXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90da3487-5ced-4ac5-bed9-eb81a3b2cad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores nulos del DataFrame uno: \n",
            "+---------+------------+----------+----------+---------+-----------+-------------+----------+----------+--------+----------------+-------------+-------------------+----------------+------------+----------+---------+--------+---------------------+---------------------+----------+\n",
            "|UNIQUE_ID|COLLISION_ID|CRASH_DATE|CRASH_TIME|PERSON_ID|PERSON_TYPE|PERSON_INJURY|VEHICLE_ID|PERSON_AGE|EJECTION|EMOTIONAL_STATUS|BODILY_INJURY|POSITION_IN_VEHICLE|SAFETY_EQUIPMENT|PED_LOCATION|PED_ACTION|COMPLAINT|PED_ROLE|CONTRIBUTING_FACTOR_1|CONTRIBUTING_FACTOR_2|PERSON_SEX|\n",
            "+---------+------------+----------+----------+---------+-----------+-------------+----------+----------+--------+----------------+-------------+-------------------+----------------+------------+----------+---------+--------+---------------------+---------------------+----------+\n",
            "|        0|           0|         0|         0|        1|          0|            0|     32430|     28605|   79871|           70451|        70429|              79810|           79826|      126971|    127003|    70431|    4676|               128263|               128279|     29508|\n",
            "+---------+------------+----------+----------+---------+-----------+-------------+----------+----------+--------+----------------+-------------+-------------------+----------------+------------+----------+---------+--------+---------------------+---------------------+----------+\n",
            "\n",
            "Valores nulos del DataFrame dos: \n",
            "+----------+----------+-------+--------+--------+---------+--------+--------------+-----------------+---------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|CRASH DATE|CRASH TIME|BOROUGH|ZIP CODE|LATITUDE|LONGITUDE|LOCATION|ON STREET NAME|CROSS STREET NAME|OFF STREET NAME|NUMBER OF PERSONS INJURED|NUMBER OF PERSONS KILLED|NUMBER OF PEDESTRIANS INJURED|NUMBER OF PEDESTRIANS KILLED|NUMBER OF CYCLIST INJURED|NUMBER OF CYCLIST KILLED|NUMBER OF MOTORIST INJURED|NUMBER OF MOTORIST KILLED|CONTRIBUTING FACTOR VEHICLE 1|CONTRIBUTING FACTOR VEHICLE 2|CONTRIBUTING FACTOR VEHICLE 3|CONTRIBUTING FACTOR VEHICLE 4|CONTRIBUTING FACTOR VEHICLE 5|COLLISION_ID|VEHICLE TYPE CODE 1|VEHICLE TYPE CODE 2|VEHICLE TYPE CODE 3|VEHICLE TYPE CODE 4|VEHICLE TYPE CODE 5|\n",
            "+----------+----------+-------+--------+--------+---------+--------+--------------+-----------------+---------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|         0|         0|  58726|   58748|   14572|    14572|   14572|         46495|            91794|         124423|                        0|                       0|                            0|                           0|                        0|                       0|                         0|                        0|                          865|                        38691|                       153691|                       166252|                       169498|           0|               2062|              56887|             154912|             166503|             169548|\n",
            "+----------+----------+-------+--------+--------+---------+--------+--------------+-----------------+---------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "\n",
            "Valores nulos del DataFrame tres: \n",
            "+----------+-----------+-----+-------+-----+---------+--------+----------+-----------+---------------+-----------------+---------+--------+---------+----------+----------+--------+---------+-------+\n",
            "|ARREST_KEY|ARREST_DATE|PD_CD|PD_DESC|KY_CD|OFNS_DESC|LAW_CODE|LAW_CAT_CD|ARREST_BORO|ARREST_PRECINCT|JURISDICTION_CODE|AGE_GROUP|PERP_SEX|PERP_RACE|X_COORD_CD|Y_COORD_CD|Latitude|Longitude|Lon_Lat|\n",
            "+----------+-----------+-----+-------+-----+---------+--------+----------+-----------+---------------+-----------------+---------+--------+---------+----------+----------+--------+---------+-------+\n",
            "|         0|          0|   57|    222|  222|      222|       5|      1501|          0|              0|                0|        0|       0|        0|         1|         1|       1|        1|      1|\n",
            "+----------+-----------+-----+-------+-----+---------+--------+----------+-----------+---------------+-----------------+---------+--------+---------+----------+----------+--------+---------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Contar valores nulos en cada columna del DataFrame 1\n",
        "missing_values_df1 = df1.agg(*[count(when(col(c).isNull(), c)).alias(c) for c in df1.columns])\n",
        "\n",
        "# Contar valores nulos en cada columna del DataFrame 2\n",
        "missing_values_df2 = df2.agg(*[count(when(col(c).isNull(), c)).alias(c) for c in df2.columns])\n",
        "\n",
        "# Contar valores nulos en cada columna del DataFrame 3\n",
        "missing_values_df3 = df3.agg(*[count(when(col(c).isNull(), c)).alias(c) for c in df3.columns])\n",
        "\n",
        "# Muestra los resultados\n",
        "print(\"Valores nulos del DataFrame uno: \")\n",
        "missing_values_df1.show()\n",
        "\n",
        "print(\"Valores nulos del DataFrame dos: \")\n",
        "missing_values_df2.show()\n",
        "\n",
        "print(\"Valores nulos del DataFrame tres: \")\n",
        "missing_values_df3.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ODHUrB_-wLy"
      },
      "source": [
        "# Técnicas para tratar los valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z_VbedeG079Q"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import mean, when\n",
        "\n",
        "# Calcular la media de las columnas numéricas en el DataFrame 1\n",
        "numeric_columns_df1 = [c for c, t in df1.dtypes if t in ['int', 'double']]\n",
        "means_df1 = df1.select([mean(col(c)).alias(c) for c in numeric_columns_df1])\n",
        "\n",
        "# Calcular la media de las columnas numéricas en el DataFrame 2\n",
        "numeric_columns_df2 = [c for c, t in df2.dtypes if t in ['int', 'double']]\n",
        "means_df2 = df2.select([mean(col(c)).alias(c) for c in numeric_columns_df2])\n",
        "\n",
        "# Calcular la media de las columnas numéricas en el DataFrame 3\n",
        "numeric_columns_df3 = [c for c, t in df3.dtypes if t in ['int', 'double']]\n",
        "means_df3 = df3.select([mean(col(c)).alias(c) for c in numeric_columns_df3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KREU42mS48IK"
      },
      "outputs": [],
      "source": [
        "# Imputar los valores nulos en el DataFrame 2 con la media\n",
        "df1_imputed = df1\n",
        "for column in numeric_columns_df1:\n",
        "    df1_imputed = df1_imputed.withColumn(column, when(col(column).isNull(), means_df1.first()[column]).otherwise(col(column)))\n",
        "\n",
        "# Imputa los valores faltantes en columnas categóricas con un valor específico (por ejemplo, \"N/A\")\n",
        "categorical_columns = [c[0] for c in df1.dtypes if c[1] == 'string']\n",
        "\n",
        "for column in categorical_columns:\n",
        "    df1 = df1.na.fill(\"N/A\", [column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AOAoExSZx2a8"
      },
      "outputs": [],
      "source": [
        "# Imputar los valores nulos en el DataFrame 2 con la media\n",
        "df2_imputed = df2\n",
        "for column in numeric_columns_df2:\n",
        "    df2_imputed = df2_imputed.withColumn(column, when(col(column).isNull(), means_df2.first()[column]).otherwise(col(column)))\n",
        "\n",
        "# Imputa los valores faltantes en columnas categóricas con un valor específico (por ejemplo, \"N/A\")\n",
        "categorical_columns = [c[0] for c in df2.dtypes if c[1] == 'string']\n",
        "\n",
        "for column in categorical_columns:\n",
        "    df2 = df2.na.fill(\"N/A\", [column])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XXraV5O85V3L"
      },
      "outputs": [],
      "source": [
        "# Imputar los valores nulos en el DataFrame 2 con la media\n",
        "df3_imputed = df3\n",
        "for column in numeric_columns_df3:\n",
        "    df3_imputed = df3_imputed.withColumn(column, when(col(column).isNull(), means_df3.first()[column]).otherwise(col(column)))\n",
        "\n",
        "# Imputa los valores faltantes en columnas categóricas con un valor específico (por ejemplo, \"N/A\")\n",
        "categorical_columns = [c[0] for c in df3.dtypes if c[1] == 'string']\n",
        "\n",
        "for column in categorical_columns:\n",
        "    df3 = df3.na.fill(\"N/A\", [column])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O30yFP734NSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db534a17-ba5a-4acc-dfe2-f15021f80699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+----------+-------------------+--------------------+-----------+-------------+--------------------+-----------------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "|  UNIQUE_ID|COLLISION_ID|CRASH_DATE|         CRASH_TIME|           PERSON_ID|PERSON_TYPE|PERSON_INJURY|          VEHICLE_ID|       PERSON_AGE|   EJECTION|EMOTIONAL_STATUS|       BODILY_INJURY| POSITION_IN_VEHICLE|  SAFETY_EQUIPMENT|        PED_LOCATION|          PED_ACTION|           COMPLAINT|       PED_ROLE|CONTRIBUTING_FACTOR_1|CONTRIBUTING_FACTOR_2|PERSON_SEX|\n",
            "+-----------+------------+----------+-------------------+--------------------+-----------+-------------+--------------------+-----------------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "|1.0249006E7|   4229554.0|10/26/2019|2023-11-12 09:43:00|31aa2bc0-f545-444...|   Occupant|  Unspecified|         1.9141108E7|37.03000082194033|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         U|\n",
            "|1.0255054E7|   4230587.0|10/25/2019|2023-11-12 15:15:00|4629e500-a73e-48d...|   Occupant|  Unspecified|         1.9144075E7|             33.0|Not Ejected|  Does Not Apply|      Does Not Apply|Front passenger, ...|Lap Belt & Harness|                NULL|                NULL|      Does Not Apply|      Passenger|                 NULL|                 NULL|         F|\n",
            "|1.0253177E7|   4230550.0|10/26/2019|2023-11-12 17:55:00|ae48c136-1383-45d...|   Occupant|  Unspecified|         1.9143133E7|             55.0|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         M|\n",
            "|  6650180.0|   3565527.0|11/21/2016|2023-11-12 13:05:00|             2782525|   Occupant|  Unspecified|1.8087574285364147E7|37.03000082194033|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|Notified Person|                 NULL|                 NULL|      NULL|\n",
            "|1.0255516E7|   4231168.0|10/25/2019|2023-11-12 11:16:00|e038e18f-40fb-447...|   Occupant|  Unspecified|         1.9144329E7|              7.0|Not Ejected|  Does Not Apply|      Does Not Apply|Right rear passen...|          Lap Belt|                NULL|                NULL|      Does Not Apply|      Passenger|                 NULL|                 NULL|         F|\n",
            "|1.0253606E7|   4230743.0|10/24/2019|2023-11-12 19:15:00|84bcb3a7-d201-4c6...|   Occupant|      Injured|         1.9143343E7|             27.0|Not Ejected|       Conscious|                Back|              Driver|Lap Belt & Harness|                NULL|                NULL|Complaint of Pain...|         Driver|                 NULL|                 NULL|         M|\n",
            "|1.0251336E7|   4230047.0|10/26/2019|2023-11-12 16:45:00|21064a07-a945-49d...|   Occupant|  Unspecified|         1.9142198E7|             41.0|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         F|\n",
            "|1.0248708E7|   4229547.0|10/26/2019|2023-11-12 01:15:00|a8904763-2870-42f...| Pedestrian|      Injured|1.8087574285364147E7|             24.0|       NULL|       Conscious|Shoulder - Upper Arm|                NULL|              NULL|Pedestrian/Bicycl...|Crossing With Signal|        None Visible|     Pedestrian|          Unspecified|          Unspecified|         F|\n",
            "|1.0250179E7|   4229808.0|10/26/2019|2023-11-12 13:04:00|c3fc715e-203f-462...|   Occupant|  Unspecified|          1.914163E7|             36.0|Not Ejected|  Does Not Apply|      Does Not Apply|              Driver|Lap Belt & Harness|                NULL|                NULL|      Does Not Apply|         Driver|                 NULL|                 NULL|         M|\n",
            "|1.0253792E7|   4230915.0|10/24/2019|2023-11-12 08:20:00|793ac6c6-cbc7-4ab...|   Occupant|  Unspecified|         1.9143438E7|37.03000082194033|       NULL|            NULL|                NULL|                NULL|              NULL|                NULL|                NULL|                NULL|     Registrant|                 NULL|                 NULL|         U|\n",
            "+-----------+------------+----------+-------------------+--------------------+-----------+-------------+--------------------+-----------------+-----------+----------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+---------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrame 1 imputados\n",
        "df1_imputed.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FEa_W7TA9_DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7029089-6f48-4f58-a35f-51b9854fc2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+---------+------------------+------------------+------------------+--------------------+--------------------+-----------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "|CRASH DATE|         CRASH TIME|  BOROUGH|          ZIP CODE|          LATITUDE|         LONGITUDE|            LOCATION|      ON STREET NAME|CROSS STREET NAME|     OFF STREET NAME|NUMBER OF PERSONS INJURED|NUMBER OF PERSONS KILLED|NUMBER OF PEDESTRIANS INJURED|NUMBER OF PEDESTRIANS KILLED|NUMBER OF CYCLIST INJURED|NUMBER OF CYCLIST KILLED|NUMBER OF MOTORIST INJURED|NUMBER OF MOTORIST KILLED|CONTRIBUTING FACTOR VEHICLE 1|CONTRIBUTING FACTOR VEHICLE 2|CONTRIBUTING FACTOR VEHICLE 3|CONTRIBUTING FACTOR VEHICLE 4|CONTRIBUTING FACTOR VEHICLE 5|COLLISION_ID|VEHICLE TYPE CODE 1| VEHICLE TYPE CODE 2|VEHICLE TYPE CODE 3|VEHICLE TYPE CODE 4|VEHICLE TYPE CODE 5|\n",
            "+----------+-------------------+---------+------------------+------------------+------------------+--------------------+--------------------+-----------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "|09/11/2021|2023-11-12 02:39:00|     NULL|10889.455499389303|40.127169389020146|-72.83116396007276|                NULL|WHITESTONE EXPRES...|        20 AVENUE|                NULL|                      2.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       2.0|                      0.0|         Aggressive Drivin...|                  Unspecified|                         NULL|                         NULL|                         NULL|   4455765.0|              Sedan|               Sedan|               NULL|               NULL|               NULL|\n",
            "|03/26/2022|2023-11-12 11:45:00|     NULL|10889.455499389303|40.127169389020146|-72.83116396007276|                NULL|QUEENSBORO BRIDGE...|             NULL|                NULL|                      1.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       1.0|                      0.0|            Pavement Slippery|                         NULL|                         NULL|                         NULL|                         NULL|   4513547.0|              Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|06/29/2022|2023-11-12 06:55:00|     NULL|10889.455499389303|40.127169389020146|-72.83116396007276|                NULL|  THROGS NECK BRIDGE|             NULL|                NULL|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|         Following Too Clo...|                  Unspecified|                         NULL|                         NULL|                         NULL|   4541903.0|              Sedan|       Pick-up Truck|               NULL|               NULL|               NULL|\n",
            "|09/11/2021|2023-11-12 09:35:00| BROOKLYN|           11208.0|         40.667202|          -73.8665|(40.667202, -73.8...|                NULL|             NULL|1211      LORING ...|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|                  Unspecified|                         NULL|                         NULL|                         NULL|                         NULL|   4456314.0|              Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 08:13:00| BROOKLYN|           11233.0|         40.683304|        -73.917274|(40.683304, -73.9...|     SARATOGA AVENUE|   DECATUR STREET|                NULL|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|                         NULL|                         NULL|                         NULL|                         NULL|                         NULL|   4486609.0|               NULL|                NULL|               NULL|               NULL|               NULL|\n",
            "|04/14/2021|2023-11-12 12:47:00|     NULL|10889.455499389303|40.127169389020146|-72.83116396007276|                NULL|MAJOR DEEGAN EXPR...|             NULL|                NULL|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|                  Unspecified|                  Unspecified|                         NULL|                         NULL|                         NULL|   4407458.0|               Dump|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 17:05:00|     NULL|10889.455499389303|         40.709183|        -73.956825|(40.709183, -73.9...|BROOKLYN QUEENS E...|             NULL|                NULL|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|          Passing Too Closely|                  Unspecified|                         NULL|                         NULL|                         NULL|   4486555.0|              Sedan|Tractor Truck Diesel|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 08:17:00|    BRONX|           10475.0|          40.86816|         -73.83148|(40.86816, -73.83...|                NULL|             NULL|344       BAYCHES...|                      2.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       2.0|                      0.0|                  Unspecified|                  Unspecified|                         NULL|                         NULL|                         NULL|   4486660.0|              Sedan|               Sedan|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 21:10:00| BROOKLYN|           11207.0|          40.67172|          -73.8971|(40.67172, -73.8971)|                NULL|             NULL|2047      PITKIN ...|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|          Driver Inexperience|                  Unspecified|                         NULL|                         NULL|                         NULL|   4487074.0|              Sedan|                NULL|               NULL|               NULL|               NULL|\n",
            "|12/14/2021|2023-11-12 14:58:00|MANHATTAN|           10017.0|          40.75144|         -73.97397|(40.75144, -73.97...|            3 AVENUE|   EAST 43 STREET|                NULL|                      0.0|                     0.0|                          0.0|                         0.0|                      0.0|                     0.0|                       0.0|                      0.0|          Passing Too Closely|                  Unspecified|                         NULL|                         NULL|                         NULL|   4486519.0|              Sedan|Station Wagon/Spo...|               NULL|               NULL|               NULL|\n",
            "+----------+-------------------+---------+------------------+------------------+------------------+--------------------+--------------------+-----------------+--------------------+-------------------------+------------------------+-----------------------------+----------------------------+-------------------------+------------------------+--------------------------+-------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+------------+-------------------+--------------------+-------------------+-------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrame 2 imputados\n",
        "df2_imputed.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SPXhQBrr-F5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0747756-a233-4173-d42c-af3bcc22efbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+-----------------+--------------------+-----------------+---------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "|  ARREST_KEY|ARREST_DATE|            PD_CD|             PD_DESC|            KY_CD|      OFNS_DESC|  LAW_CODE|LAW_CAT_CD|ARREST_BORO|ARREST_PRECINCT|JURISDICTION_CODE|AGE_GROUP|PERP_SEX|     PERP_RACE|        X_COORD_CD|       Y_COORD_CD|          Latitude|         Longitude|             Lon_Lat|\n",
            "+------------+-----------+-----------------+--------------------+-----------------+---------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "|2.36791704E8| 11/22/2021|            581.0|                NULL|254.4677216376148|           NULL|PL 2225001|         M|          M|           28.0|              0.0|    45-64|       M|         BLACK|          997427.0|         230378.0|40.799008797000056|-73.95240854099995|POINT (-73.952408...|\n",
            "| 2.3735474E8| 12/04/2021|            153.0|              RAPE 3|            104.0|           RAPE|PL 1302502|         F|          B|           41.0|              0.0|    25-44|       M|WHITE HISPANIC|         1013232.0|         236725.0|40.816391847000034|-73.89529641399997|POINT (-73.895296...|\n",
            "|2.36081433E8| 11/09/2021|            681.0|CHILD, ENDANGERIN...|            233.0|     SEX CRIMES|PL 2601001|         M|          Q|          113.0|              0.0|    25-44|       M|         BLACK|         1046367.0|         186986.0| 40.67970040800003|-73.77604736799998|POINT (-73.776047...|\n",
            "|  3.231138E7| 06/18/2007|            511.0|CONTROLLED SUBSTA...|            235.0|DANGEROUS DRUGS|PL 2200300|         M|          Q|           27.0|              1.0|    18-24|       M|         BLACK|1005571.8431609577|208195.2402222983|40.738080425262254|-73.92303425260204|                NULL|\n",
            "|1.92799737E8| 01/26/2019|            177.0|        SEXUAL ABUSE|            116.0|     SEX CRIMES|PL 1306503|         F|          M|           25.0|              0.0|    45-64|       M|         BLACK|         1000555.0|         230994.0|40.800694331000045|-73.94110928599997|POINT (-73.941109...|\n",
            "|1.93260691E8| 02/06/2019|435.2008507223114|                NULL|254.4677216376148|           NULL|PL 2203400|         F|          M|           14.0|              0.0|    25-44|       M|       UNKNOWN|          986685.0|         215375.0| 40.75783900300007|-73.99121211099998|POINT (-73.991212...|\n",
            "|2.37291769E8| 12/03/2021|            579.0|                NULL|254.4677216376148|           NULL|PL 2224001|         F|          Q|          115.0|              0.0|    25-44|       M|         BLACK|         1018534.0|         220579.0| 40.77205649600006|-73.87622400099998|POINT (-73.876224...|\n",
            "|2.36106641E8| 11/10/2021|            263.0|         ARSON 2,3,4|            114.0|          ARSON|PL 1501001|         F|          B|           41.0|             72.0|    25-44|       M|WHITE HISPANIC|         1017934.0|         232221.0|40.804012949000025|-73.87833183299993|POINT (-73.878331...|\n",
            "|2.38383628E8| 12/28/2021|            729.0|FORGERY,ETC.,UNCL...|            113.0|        FORGERY|PL 1702500|         F|          Q|          113.0|              0.0|    18-24|       M|         BLACK|         1045482.0|         191341.0| 40.69166001700007|-73.77919852099996|POINT (-73.779198...|\n",
            "|1.49117452E8| 01/06/2016|            153.0|              RAPE 3|            104.0|           RAPE|PL 1302503|         F|          K|           67.0|              0.0|    25-44|       M|         BLACK|          998032.0|         175598.0|40.648650085000035|-73.95033556299995|POINT (-73.950335...|\n",
            "+------------+-----------+-----------------+--------------------+-----------------+---------------+----------+----------+-----------+---------------+-----------------+---------+--------+--------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrame 3 imputados\n",
        "df3_imputed.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Xh2AicbuhNI8"
      },
      "outputs": [],
      "source": [
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qm2jk7L1U3MG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_date, year, month, date_format\n",
        "import folium\n",
        "\n",
        "# 1. Convertir la columna \"CRASH_DATE\" a tipo Date y extraer el año y el mes\n",
        "df1_imputed = df1_imputed.withColumn(\"CRASH_DATE\", to_date(\"CRASH_DATE\", \"MM/dd/yyyy\"))\n",
        "df1_imputed = df1_imputed.withColumn(\"CRASH_YEAR\", year(\"CRASH_DATE\"))\n",
        "df1_imputed = df1_imputed.withColumn(\"CRASH_MONTH\", month(\"CRASH_DATE\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "atUQ5gAcU7uU"
      },
      "outputs": [],
      "source": [
        "# Contar las causas de accidentes\n",
        "causas_accidentes = df1_imputed.groupBy(\"CONTRIBUTING_FACTOR_1\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sQqZ3EI_U9X9"
      },
      "outputs": [],
      "source": [
        "# Analizar la evolución de las causas en el tiempo\n",
        "causas_por_fecha = df1_imputed.groupBy(\"CRASH_YEAR\", \"CRASH_MONTH\", \"CONTRIBUTING_FACTOR_1\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GceNVEJFVGz9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, count, when, mean, to_date\n",
        "import folium\n",
        "\n",
        "# Crear un mapa con marcadores de accidentes\n",
        "m = folium.Map(location=[40.7128, -74.0060], zoom_start=10)\n",
        "\n",
        "# Utiliza show() para mostrar una muestra de los datos en lugar de collect()\n",
        "sample_data = df2_imputed.limit(100).collect()\n",
        "\n",
        "for row in sample_data:\n",
        "    folium.Marker([row[\"LATITUDE\"], row[\"LONGITUDE\"]]).add_to(m)\n",
        "\n",
        "m.save('mapa_accidentes.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mAZtcm5CceoQ"
      },
      "outputs": [],
      "source": [
        "# 4. Analizar grupos demográficos en arrestos\n",
        "grupos_demograficos_arrestos = df3_imputed.select(\"PERP_SEX\", \"AGE_GROUP\", \"PERP_RACE\")\n",
        "\n",
        "# Analizar grupos demográficos en accidentes\n",
        "grupos_demograficos_accidentes = df1_imputed.select(\"PERSON_SEX\", \"PERSON_AGE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ztIF8O7UWVtS"
      },
      "outputs": [],
      "source": [
        "# 5. Analizar patrones horarios, diarios y estacionales en accidentes\n",
        "df1_imputed = df1_imputed.withColumn(\"CRASH_TIME\", date_format(\"CRASH_DATE\", \"HH\"))\n",
        "df1_imputed = df1_imputed.withColumn(\"DAY_OF_WEEK\", date_format(\"CRASH_DATE\", \"u\"))\n",
        "df1_imputed = df1_imputed.withColumn(\"MONTH\", date_format(\"CRASH_DATE\", \"MM\"))\n",
        "\n",
        "patrones_horarios = df1_imputed.groupBy(\"CRASH_TIME\").count()\n",
        "patrones_diarios = df1_imputed.groupBy(\"DAY_OF_WEEK\").count()\n",
        "patrones_estacionales = df1_imputed.groupBy(\"MONTH\").count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XQAAA7zBWXpR"
      },
      "outputs": [],
      "source": [
        "# 6. Calcular la tasa de reincidencia en arrestos y accidentes\n",
        "tasa_reincidencia_arrestos = df3_imputed.dropDuplicates([\"ARREST_KEY\"]).count() / df3_imputed.count()\n",
        "tasa_reincidencia_accidentes = df1_imputed.dropDuplicates([\"UNIQUE_ID\"]).count() / df1_imputed.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzMDaSFEWsNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0579816f-c76c-4207-aed5-577b4d829433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---------+--------------------+\n",
            "|summary|PERP_SEX|AGE_GROUP|           PERP_RACE|\n",
            "+-------+--------+---------+--------------------+\n",
            "|  count|  186957|   186957|              186957|\n",
            "|   mean|    NULL|     NULL|                NULL|\n",
            "| stddev|    NULL|     NULL|                NULL|\n",
            "|    min|       F|    18-24|AMERICAN INDIAN/A...|\n",
            "|    max|       M|      <18|      WHITE HISPANIC|\n",
            "+-------+--------+---------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostrar una vista previa de los datos\n",
        "descripcion_arrestos = grupos_demograficos_arrestos.describe()\n",
        "descripcion_accidentes = grupos_demograficos_accidentes.describe()\n",
        "descripcion_arrestos.show()\n",
        "descripcion_accidentes.show()\n",
        "patrones_horarios.show()\n",
        "patrones_diarios.show()\n",
        "patrones_estacionales.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Cuáles son las causas más comunes de accidentes en el conjunto de datos?\n",
        "causas_accidentes = df1_imputed.groupBy(\"CONTRIBUTING_FACTOR_1\").count()\n",
        "causas_accidentes.orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "id": "9-QPBsZXWBFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¿Cómo ha evolucionado la frecuencia de las causas de accidentes a lo largo de los años y meses?\n",
        "causas_por_fecha = df1_imputed.groupBy(\"CRASH_YEAR\", \"CRASH_MONTH\", \"CONTRIBUTING_FACTOR_1\").count()\n",
        "causas_por_fecha.orderBy(\"CRASH_YEAR\", \"CRASH_MONTH\").show()"
      ],
      "metadata": {
        "id": "kByiO4mfYNm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¿En qué áreas geográficas se concentran los accidentes?\n",
        "from pyspark.sql.functions import col, count, when, mean, to_date\n",
        "import folium\n",
        "\n",
        "# Crear un mapa con marcadores de accidentes\n",
        "m = folium.Map(location=[40.7128, -74.0060], zoom_start=10)\n",
        "\n",
        "# Utiliza show() para mostrar una muestra de los datos en lugar de collect()\n",
        "sample_data = df2_imputed.limit(100).collect()\n",
        "\n",
        "for row in sample_data:\n",
        "    folium.Marker([row[\"LATITUDE\"], row[\"LONGITUDE\"]]).add_to(m)\n",
        "\n",
        "m.save('mapa_accidentes.html')\n"
      ],
      "metadata": {
        "id": "V9G-aYh7YU0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¿Hay disparidades demográficas en la distribución de arrestos y accidentes?\n",
        "grupos_demograficos_arrestos = df3_imputed.groupBy(\"PERP_SEX\", \"AGE_GROUP\", \"PERP_RACE\").count()\n",
        "grupos_demograficos_arrestos.show()\n",
        "\n",
        "grupos_demograficos_accidentes = df1_imputed.groupBy(\"PERSON_SEX\", \"PERSON_AGE\").count()\n",
        "grupos_demograficos_accidentes.show()\n"
      ],
      "metadata": {
        "id": "c9opT0u2YvWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#¿Cuáles son los momentos del día, días de la semana o meses con una mayor incidencia de accidentes?\n",
        "patrones_horarios = df1_imputed.groupBy(\"CRASH_TIME\").count()\n",
        "patrones_horarios.orderBy(\"count\", ascending=False).show()\n",
        "\n",
        "patrones_diarios = df1_imputed.groupBy(\"DAY_OF_WEEK\").count()\n",
        "patrones_diarios.orderBy(\"DAY_OF_WEEK\").show()\n",
        "\n",
        "patrones_estacionales = df1_imputed.groupBy(\"MONTH\").count()\n",
        "patrones_estacionales.orderBy(\"MONTH\").show()\n"
      ],
      "metadata": {
        "id": "R3hnOGedY5sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Cuál es la tasa de reincidencia en arrestos y accidentes?\n",
        "tasa_reincidencia_arrestos = df3_imputed.dropDuplicates([\"ARREST_KEY\"]).count() / df3_imputed.count()\n",
        "print(\"Tasa de reincidencia en arrestos:\", tasa_reincidencia_arrestos)\n",
        "\n",
        "tasa_reincidencia_accidentes = df1_imputed.dropDuplicates([\"UNIQUE_ID\"]).count() / df1_imputed.count()\n",
        "print(\"Tasa de reincidencia en accidentes:\", tasa_reincidencia_accidentes)\n"
      ],
      "metadata": {
        "id": "DdQRxLqkZCnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXGrcPPPU1LW"
      },
      "source": [
        "------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3-168QnEuxx"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "# Analizar la evolución de las causas en el tiempo\n",
        "# Convertir la columna \"CRASH_DATE\" a tipo Date\n",
        "df1_imputed = df1_imputed.withColumn(\"CRASH_DATE\", to_date(\"CRASH_DATE\", \"MM/dd/yyyy\"))\n",
        "\n",
        "# Contar las causas de accidentes\n",
        "causas_accidentes = df1_imputed.groupBy(\"CONTRIBUTING_FACTOR_1\").count()\n",
        "\n",
        "# Analizar la evolución de las causas en el tiempo\n",
        "causas_por_fecha = df1_imputed.groupBy(\"CRASH_DATE\", \"CONTRIBUTING_FACTOR_1\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O53k6ng_FnC1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, count, when, mean, to_date\n",
        "import folium\n",
        "\n",
        "# Crear un mapa con marcadores de accidentes\n",
        "m = folium.Map(location=[40.7128, -74.0060], zoom_start=10)\n",
        "\n",
        "# Utiliza show() para mostrar una muestra de los datos en lugar de collect()\n",
        "sample_data = df2_imputed.limit(100).collect()\n",
        "\n",
        "for row in sample_data:\n",
        "    folium.Marker([row[\"LATITUDE\"], row[\"LONGITUDE\"]]).add_to(m)\n",
        "\n",
        "m.save('mapa_accidentes.html')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edt7lJTgLeGq"
      },
      "outputs": [],
      "source": [
        "# Analizar grupos demográficos en arrestos\n",
        "grupos_demograficos_arrestos = df3_imputed.select(\"PERP_SEX\", \"AGE_GROUP\", \"PERP_RACE\")\n",
        "\n",
        "# Analizar grupos demográficos en accidentes\n",
        "grupos_demograficos_accidentes = df1_imputed.select(\"PERSON_SEX\", \"PERSON_AGE\")\n",
        "\n",
        "# Realizar análisis descriptivo\n",
        "descripcion_arrestos = grupos_demograficos_arrestos.describe()\n",
        "descripcion_accidentes = grupos_demograficos_accidentes.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxp7xFi4Lp4D"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import hour, dayofweek, month\n",
        "\n",
        "# Analizar patrones horarios en accidentes\n",
        "df2_imputed = df2_imputed.withColumn(\"CRASH_TIME\", to_date(\"CRASH TIME\", \"MM/dd/yyyy HH:mm:ss\"))\n",
        "patrones_horarios = df2_imputed.groupBy(hour(\"CRASH_TIME\")).count()\n",
        "\n",
        "# Analizar patrones diarios en accidentes\n",
        "patrones_diarios = df2_imputed.groupBy(dayofweek(\"CRASH_TIME\")).count()\n",
        "\n",
        "# Analizar patrones estacionales en accidentes\n",
        "patrones_estacionales = df2_imputed.groupBy(month(\"CRASH_TIME\")).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsXvl11QLvb2"
      },
      "outputs": [],
      "source": [
        "# Calcular la tasa de reincidencia en arrestos\n",
        "tasa_reincidencia_arrestos = df3_imputed.dropDuplicates([\"ARREST_KEY\"]).count() / df3_imputed.count()\n",
        "\n",
        "# Calcular la tasa de reincidencia en accidentes\n",
        "tasa_reincidencia_accidentes = df1_imputed.dropDuplicates([\"UNIQUE_ID\"]).count() / df1_imputed.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lthn99IrMTBT"
      },
      "outputs": [],
      "source": [
        "# Mostrar una vista previa de los datos\n",
        "descripcion_arrestos.show()\n",
        "descripcion_accidentes.show()\n",
        "patrones_horarios.show()\n",
        "patrones_diarios.show()\n",
        "patrones_estacionales.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdARHNmEh8wf"
      },
      "source": [
        "#*Preparación previa de los datos para la implementación de los modelos*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIkvjzZRVchS"
      },
      "source": [
        "# Correlaciones"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import NumericType\n",
        "\n",
        "# Seleccionar las columnas numéricas del DataFrame\n",
        "numeric_cols = [column for column in df1_imputed.columns\n",
        "                if df1_imputed.schema[column].dataType in [NumericType()]]\n",
        "\n",
        "# Verificar si hay suficientes columnas numéricas\n",
        "if len(numeric_cols) < 2:\n",
        "    print(\"No hay suficientes columnas numéricas para calcular la matriz de correlación.\")\n",
        "else:\n",
        "    # Crear un VectorAssembler para combinar las columnas numéricas en un solo vector\n",
        "    assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
        "    assembled_df = assembler.transform(df1_imputed)\n",
        "\n",
        "    # Calcular la matriz de correlación\n",
        "    correlation_matrix = Correlation.corr(assembled_df, \"features\")\n",
        "\n",
        "    # Obtener la matriz de correlación como un array de NumPy\n",
        "    correlation_array = correlation_matrix.collect()[0][\"pearson(features)\"].values\n",
        "\n",
        "    # Imprimir la matriz de correlación\n",
        "    print(\"Matriz de Correlación:\")\n",
        "    print(correlation_array)"
      ],
      "metadata": {
        "id": "cPqes9kvm_N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import NumericType\n",
        "\n",
        "# Seleccionar las columnas numéricas del DataFrame\n",
        "numeric_cols = [column for column in df2_imputed.columns\n",
        "                if df2_imputed.schema[column].dataType in [NumericType()]]\n",
        "\n",
        "# Verificar si hay suficientes columnas numéricas\n",
        "if len(numeric_cols) < 2:\n",
        "    print(\"No hay suficientes columnas numéricas para calcular la matriz de correlación.\")\n",
        "else:\n",
        "    # Crear un VectorAssembler para combinar las columnas numéricas en un solo vector\n",
        "    assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
        "    assembled_df = assembler.transform(df2_imputed)\n",
        "\n",
        "    # Calcular la matriz de correlación\n",
        "    correlation_matrix = Correlation.corr(assembled_df, \"features\")\n",
        "\n",
        "    # Obtener la matriz de correlación como un array de NumPy\n",
        "    correlation_array = correlation_matrix.collect()[0][\"pearson(features)\"].values\n",
        "\n",
        "    # Imprimir la matriz de correlación\n",
        "    print(\"Matriz de Correlación:\")\n",
        "    print(correlation_array)"
      ],
      "metadata": {
        "id": "rQsrxV8hGj3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import NumericType\n",
        "\n",
        "# Seleccionar las columnas numéricas del DataFrame\n",
        "numeric_cols = [column for column in df3_imputed.columns\n",
        "                if df3_imputed.schema[column].dataType in [NumericType()]]\n",
        "\n",
        "# Verificar si hay suficientes columnas numéricas\n",
        "if len(numeric_cols) < 2:\n",
        "    print(\"No hay suficientes columnas numéricas para calcular la matriz de correlación.\")\n",
        "else:\n",
        "    # Crear un VectorAssembler para combinar las columnas numéricas en un solo vector\n",
        "    assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
        "    assembled_df = assembler.transform(df3_imputed)\n",
        "\n",
        "    # Calcular la matriz de correlación\n",
        "    correlation_matrix = Correlation.corr(assembled_df, \"features\")\n",
        "\n",
        "    # Obtener la matriz de correlación como un array de NumPy\n",
        "    correlation_array = correlation_matrix.collect()[0][\"pearson(features)\"].values\n",
        "\n",
        "    # Imprimir la matriz de correlación\n",
        "    print(\"Matriz de Correlación:\")\n",
        "    print(correlation_array)"
      ],
      "metadata": {
        "id": "69rUtjBpIwtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicación de tecnicas"
      ],
      "metadata": {
        "id": "2aRSUT7Dl27t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalización"
      ],
      "metadata": {
        "id": "XRcf24Y3OLrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Columnas a normalizar\n",
        "columns_to_normalize = ['PERSON_AGE', 'VEHICLE_ID', 'COLLISION_ID']\n",
        "\n",
        "# Crear un ensamblador de características\n",
        "assembler = VectorAssembler(inputCols=columns_to_normalize, outputCol='features')\n",
        "\n",
        "# Crear un escalador MinMax\n",
        "scaler = MinMaxScaler(inputCol='features', outputCol='scaled_features')\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "# Ajustar y transformar el conjunto de datos\n",
        "model = pipeline.fit(df1_imputed)\n",
        "df_normalized = model.transform(df1_imputed)\n",
        "\n",
        "# Mostrar el conjunto de datos resultante\n",
        "df_normalized.select('PERSON_AGE', 'VEHICLE_ID', 'COLLISION_ID', 'scaled_features').show(10, truncate=False)"
      ],
      "metadata": {
        "id": "u_fLqvwdN-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Lista de columnas a normalizar\n",
        "columns_to_normalize = [\n",
        "    \"LATITUDE\",\n",
        "    \"LONGITUDE\",\n",
        "    \"NUMBER OF PERSONS INJURED\",\n",
        "    \"NUMBER OF PERSONS KILLED\",\n",
        "    \"NUMBER OF PEDESTRIANS INJURED\",\n",
        "    \"NUMBER OF PEDESTRIANS KILLED\",\n",
        "    \"NUMBER OF CYCLIST INJURED\",\n",
        "    \"NUMBER OF CYCLIST KILLED\",\n",
        "    \"NUMBER OF MOTORIST INJURED\",\n",
        "    \"NUMBER OF MOTORIST KILLED\"\n",
        "]\n",
        "\n",
        "# Crear un ensamblador de características\n",
        "assembler = VectorAssembler(inputCols=columns_to_normalize, outputCol=\"features\")\n",
        "\n",
        "# Crear el escalador estándar\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "# Crear un pipeline\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "# Aplicar el pipeline al DataFrame\n",
        "df2_imputed_normalized = pipeline.fit(df2_imputed).transform(df2_imputed)\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "df2_imputed_normalized.select(\"scaled_features\").show(truncate=False)"
      ],
      "metadata": {
        "id": "EJilUdx4R3EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "\n",
        "numerical_columns = [\"ARREST_KEY\", \"PD_CD\", \"KY_CD\", \"ARREST_PRECINCT\", \"JURISDICTION_CODE\", \"X_COORD_CD\", \"Y_COORD_CD\", \"Latitude\", \"Longitude\"]\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"features\")\n",
        "\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "df_scaled = pipeline.fit(df3_imputed).transform(df3_imputed)\n",
        "\n",
        "df_scaled.select(\"scaled_features\").show(truncate=False)"
      ],
      "metadata": {
        "id": "byCJFJaeR9Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión"
      ],
      "metadata": {
        "id": "LmIyJTYdl5-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Seleccionar las columnas relevantes y eliminar las filas con valores nulos\n",
        "selected_columns = ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO', 'ARREST_PRECINCT', 'JURISDICTION_CODE']\n",
        "df3_selected = df3_imputed.select(selected_columns).na.drop()\n",
        "\n",
        "# Convertir variables categóricas a numéricas utilizando StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df3_selected) for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']]\n",
        "\n",
        "# Ensamblar las características en un solo vector\n",
        "assembler = VectorAssembler(inputCols=[column+\"_index\" for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']], outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de regresión lineal\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"JURISDICTION_CODE\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "(training_data, testing_data) = df3_selected.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Ajustar el modelo al conjunto de entrenamiento\n",
        "model1r = pipeline.fit(training_data)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = model1r.transform(testing_data)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "evaluator = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "# Imprimir los coeficientes del modelo\n",
        "print(\"Coefficients: %s\" % str(model1r.stages[-1].coefficients))\n",
        "print(\"Intercept: %s\" % str(model1r.stages[-1].intercept))\n"
      ],
      "metadata": {
        "id": "TBAbeWKlcski"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Seleccionar las columnas relevantes y eliminar las filas con valores nulos\n",
        "selected_columns = ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO', 'ARREST_PRECINCT', 'JURISDICTION_CODE']\n",
        "df3_selected = df3_imputed.select(selected_columns).na.drop()\n",
        "\n",
        "# Convertir variables categóricas a numéricas utilizando StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df3_selected) for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']]\n",
        "\n",
        "# Ensamblar las características en un solo vector\n",
        "assembler = VectorAssembler(inputCols=[column+\"_index\" for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']], outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de regresión lineal\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"JURISDICTION_CODE\", maxIter=20, regParam=0.01, elasticNetParam=0.5)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "(training_data, testing_data) = df3_selected.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Ajustar el modelo al conjunto de entrenamiento\n",
        "model2r = pipeline.fit(training_data)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = model2r.transform(testing_data)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "evaluator = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "# Imprimir los coeficientes del modelo\n",
        "print(\"Coefficients: %s\" % str(model2r.stages[-1].coefficients))\n",
        "print(\"Intercept: %s\" % str(model2r.stages[-1].intercept))"
      ],
      "metadata": {
        "id": "zzY_E7jCwPLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Seleccionar las columnas relevantes y eliminar las filas con valores nulos\n",
        "selected_columns = ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO', 'ARREST_PRECINCT', 'JURISDICTION_CODE']\n",
        "df3_selected = df3_imputed.select(selected_columns).na.drop()\n",
        "\n",
        "# Convertir variables categóricas a numéricas utilizando StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df3_selected) for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']]\n",
        "\n",
        "# Ensamblar las características en un solo vector\n",
        "assembler = VectorAssembler(inputCols=[column+\"_index\" for column in ['AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'LAW_CAT_CD', 'ARREST_BORO']], outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de regresión lineal\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\",labelCol=\"JURISDICTION_CODE\",maxIter=30, regParam=0.05,elasticNetParam=0.1,tol=1e-6,fitIntercept=True,standardization=True,aggregationDepth=2\n",
        ")\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "(training_data, testing_data) = df3_selected.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Ajustar el modelo al conjunto de entrenamiento\n",
        "model3r = pipeline.fit(training_data)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = model2r.transform(testing_data)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "evaluator = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "# Imprimir los coeficientes del modelo\n",
        "print(\"Coefficients: %s\" % str(model3r.stages[-1].coefficients))\n",
        "print(\"Intercept: %s\" % str(model3r.stages[-1].intercept))"
      ],
      "metadata": {
        "id": "Xo7ZY00cw_eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "78IdBN4Mkhyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "# Seleccionar las columnas relevantes\n",
        "selected_columns = ['LATITUDE', 'LONGITUDE', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
        "                    'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
        "                    'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
        "                    'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']\n",
        "\n",
        "# Filtrar el dataframe y seleccionar las columnas relevantes\n",
        "df_selected = df2_imputed.select(selected_columns)\n",
        "\n",
        "# Crear un VectorAssembler para combinar las características en una columna de características\n",
        "vec_assembler = VectorAssembler(inputCols=selected_columns, outputCol=\"features\")\n",
        "\n",
        "# Crear un modelo de KMeans con el número de clústeres deseado\n",
        "kmeans = KMeans().setK(5).setSeed(1)\n",
        "\n",
        "# Crear un pipeline con el VectorAssembler y el modelo de KMeans\n",
        "pipeline = Pipeline(stages=[vec_assembler, kmeans])\n",
        "\n",
        "# Ajustar el modelo al dataframe\n",
        "model1c = pipeline.fit(df_selected)\n",
        "\n",
        "# Predecir los clústeres para cada fila en el dataframe\n",
        "df_clusters1c = model1c.transform(df_selected)\n",
        "\n",
        "# Mostrar los resultados\n",
        "df_clusters1c.select('features', 'prediction').show()"
      ],
      "metadata": {
        "id": "CnhWwR3J3MIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Convertir el DataFrame de PySpark a un DataFrame de Pandas para la visualización\n",
        "pd_df = df_clusters1c.select('features', 'prediction').toPandas()\n",
        "\n",
        "# Obtener las columnas relevantes\n",
        "features = pd_df['features'].apply(lambda x: x.toArray())\n",
        "pd_df = pd.concat([pd_df.drop(['features'], axis=1), pd.DataFrame(features.tolist())], axis=1)\n",
        "\n",
        "# Gráfico 3D\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Colores para cada clúster\n",
        "colors = {0: 'red', 1: 'green', 2: 'blue'}\n",
        "\n",
        "# Scatter plot\n",
        "for cluster, color in colors.items():\n",
        "    cluster_data = pd_df[pd_df['prediction'] == cluster]\n",
        "    ax.scatter(cluster_data[0], cluster_data[1], cluster_data[2], c=color, label=f'Cluster {cluster}')\n",
        "\n",
        "# Etiquetas y título\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('KMeans Clustering')\n",
        "\n",
        "# Leyenda\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xjN9-3TuE5q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "# Seleccionar las columnas relevantes\n",
        "selected_columns = ['LATITUDE', 'LONGITUDE', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
        "                    'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
        "                    'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
        "                    'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']\n",
        "\n",
        "# Filtrar el dataframe y seleccionar las columnas relevantes\n",
        "df_selected = df2_imputed.select(selected_columns)\n",
        "\n",
        "# Crear un VectorAssembler para combinar las características en una columna de características\n",
        "vec_assembler = VectorAssembler(inputCols=selected_columns, outputCol=\"features\")\n",
        "\n",
        "# Model 2: Cambiar el número de clústeres y la semilla\n",
        "kmeans2 = KMeans().setK(8).setSeed(2)  # Cambiar el número de clústeres y la semilla\n",
        "\n",
        "# Crear un nuevo pipeline con el mismo VectorAssembler y el nuevo modelo de KMeans\n",
        "pipeline2 = Pipeline(stages=[vec_assembler, kmeans2])\n",
        "\n",
        "# Ajustar el modelo al dataframe\n",
        "model2c = pipeline2.fit(df_selected)\n",
        "\n",
        "# Predecir los clústeres para cada fila en el dataframe\n",
        "df_clusters2c = model2c.transform(df_selected)\n",
        "\n",
        "# Mostrar los resultados\n",
        "df_clusters2c.select('features', 'prediction').show()"
      ],
      "metadata": {
        "id": "gYlJXSHL6mH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Convertir el DataFrame de PySpark a un DataFrame de Pandas para la visualización\n",
        "pd_df = df_clusters2c.select('features', 'prediction').toPandas()\n",
        "\n",
        "# Obtener las columnas relevantes\n",
        "features = pd_df['features'].apply(lambda x: x.toArray())\n",
        "pd_df = pd.concat([pd_df.drop(['features'], axis=1), pd.DataFrame(features.tolist())], axis=1)\n",
        "\n",
        "# Gráfico 3D\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Colores para cada clúster\n",
        "colors = {0: 'red', 1: 'green', 2: 'blue'}\n",
        "\n",
        "# Scatter plot\n",
        "for cluster, color in colors.items():\n",
        "    cluster_data = pd_df[pd_df['prediction'] == cluster]\n",
        "    ax.scatter(cluster_data[0], cluster_data[1], cluster_data[2], c=color, label=f'Cluster {cluster}')\n",
        "\n",
        "# Etiquetas y título\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('KMeans Clustering')\n",
        "\n",
        "# Leyenda\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wGF2ajROEkDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "# Seleccionar las columnas relevantes\n",
        "selected_columns = ['LATITUDE', 'LONGITUDE', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
        "                    'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
        "                    'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
        "                    'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']\n",
        "\n",
        "# Filtrar el dataframe y seleccionar las columnas relevantes\n",
        "df_selected = df2_imputed.select(selected_columns)\n",
        "\n",
        "# Crear un VectorAssembler para combinar las características en una columna de características\n",
        "vec_assembler = VectorAssembler(inputCols=selected_columns, outputCol=\"features\")\n",
        "\n",
        "# Model 3: Cambiar otros hiperparámetros según sea necesario\n",
        "kmeans3 = KMeans().setK(3).setSeed(3).setMaxIter(20)  # Cambiar el número de clústeres, la semilla y el número máximo de iteraciones\n",
        "\n",
        "# Crear un nuevo pipeline con el mismo VectorAssembler y el nuevo modelo de KMeans\n",
        "pipeline3 = Pipeline(stages=[vec_assembler, kmeans3])\n",
        "\n",
        "# Ajustar el modelo al dataframe\n",
        "model3c = pipeline3.fit(df_selected)\n",
        "\n",
        "# Predecir los clústeres para cada fila en el dataframe\n",
        "df_clusters3c = model3c.transform(df_selected)\n",
        "\n",
        "# Mostrar los resultados\n",
        "df_clusters3c.select('features', 'prediction').show()"
      ],
      "metadata": {
        "id": "I9BN6QzC7ywR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Convertir el DataFrame de PySpark a un DataFrame de Pandas para la visualización\n",
        "pd_df = df_clusters3c.select('features', 'prediction').toPandas()\n",
        "\n",
        "# Obtener las columnas relevantes\n",
        "features = pd_df['features'].apply(lambda x: x.toArray())\n",
        "pd_df = pd.concat([pd_df.drop(['features'], axis=1), pd.DataFrame(features.tolist())], axis=1)\n",
        "\n",
        "# Gráfico 3D\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Colores para cada clúster\n",
        "colors = {0: 'red', 1: 'green', 2: 'blue'}\n",
        "\n",
        "# Scatter plot\n",
        "for cluster, color in colors.items():\n",
        "    cluster_data = pd_df[pd_df['prediction'] == cluster]\n",
        "    ax.scatter(cluster_data[0], cluster_data[1], cluster_data[2], c=color, label=f'Cluster {cluster}')\n",
        "\n",
        "# Etiquetas y título\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('KMeans Clustering')\n",
        "\n",
        "# Leyenda\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RG7xUqqyB6TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Evaluación*"
      ],
      "metadata": {
        "id": "_TSnQeO5udPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion"
      ],
      "metadata": {
        "id": "9acZJCiYunRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "import pandas as pd\n",
        "\n",
        "# Define function for evaluation metrics\n",
        "def evaluate_model(predictions):\n",
        "    evaluator_rmse = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "    evaluator_mae = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "    evaluator_r2 = RegressionEvaluator(labelCol=\"JURISDICTION_CODE\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "    rmse = evaluator_rmse.evaluate(predictions)\n",
        "    mae = evaluator_mae.evaluate(predictions)\n",
        "    r2 = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "    # Calculate explained variance\n",
        "    metrics = RegressionMetrics(predictions.select(\"prediction\", \"JURISDICTION_CODE\").rdd.map(lambda x: (float(x[0]), float(x[1]))))\n",
        "    explained_variance = metrics.explainedVariance\n",
        "\n",
        "    return rmse, mae, r2, explained_variance\n",
        "\n",
        "# Evaluate model1r\n",
        "predictions1 = model1r.transform(testing_data)\n",
        "rmse1, mae1, r2_1, explained_variance1 = evaluate_model(predictions1)\n",
        "\n",
        "# Evaluate model2r\n",
        "predictions2 = model2r.transform(testing_data)\n",
        "rmse2, mae2, r2_2, explained_variance2 = evaluate_model(predictions2)\n",
        "\n",
        "# Evaluate model3r\n",
        "predictions3 = model3r.transform(testing_data)\n",
        "rmse3, mae3, r2_3, explained_variance3 = evaluate_model(predictions3)\n",
        "\n",
        "# Create a table\n",
        "data = {\n",
        "    'Metric': ['RMSE', 'MAE', 'R-squared', 'Explained Variance'],\n",
        "    'Model 1': [rmse1, mae1, r2_1, explained_variance1],\n",
        "    'Model 2': [rmse2, mae2, r2_2, explained_variance2],\n",
        "    'Model 3': [rmse3, mae3, r2_3, explained_variance3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "OJ5B_lvCkpuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "H7FDPD6Muo_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "# Métricas de evaluación\n",
        "evaluator = ClusteringEvaluator()\n",
        "\n",
        "# Silueta\n",
        "silhouette1 = evaluator.evaluate(df_clusters1c)\n",
        "silhouette2 = evaluator.evaluate(df_clusters2c)\n",
        "silhouette3 = evaluator.evaluate(df_clusters3c)\n",
        "\n",
        "# Inercia\n",
        "inertia1 = model1c.stages[-1].summary.trainingCost\n",
        "inertia2 = model2c.stages[-1].summary.trainingCost\n",
        "inertia3 = model3c.stages[-1].summary.trainingCost\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"\\nResultados de la evaluación:\")\n",
        "print(\"\\n| Métrica     | Modelo 1 | Modelo 2 | Modelo 3 |\")\n",
        "print(\"|-------------|----------|----------|----------|\")\n",
        "print(f\"| Silueta     | {silhouette1:.4f}  | {silhouette2:.4f}  | {silhouette3:.4f}  |\")\n",
        "print(f\"| Inercia     | {inertia1:.4f}  | {inertia2:.4f}  | {inertia3:.4f}  |\")"
      ],
      "metadata": {
        "id": "yAOg5ZMx63p1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}